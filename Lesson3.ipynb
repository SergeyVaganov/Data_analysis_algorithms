{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание \n",
    "1. *Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log.\n",
    "2. Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным.\n",
    "3. Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba).\n",
    "4. Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred).\n",
    "5. *Реализуйте функции для подсчета Accuracy, матрицы ошибок, точности и полноты, а также F1 score.\n",
    "6. Могла ли модель переобучиться? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([ [   1,    1,  500,    1],\n",
    "               [   1,    1,  700,    1],\n",
    "               [   1,    2,  750,    2],\n",
    "               [   1,    5,  600,    1],\n",
    "               [   1,    3, 1450,    2],\n",
    "               [   1,    0,  800,    1],\n",
    "               [   1,    5, 1500,    3],\n",
    "               [   1,   10, 2000,    3],\n",
    "               [   1,    1,  450,    1],\n",
    "               [   1,    2, 1000,    2]], dtype=np.float64)\n",
    "\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scale(x):\n",
    "    res = (x - x.mean()) / x.std()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_st = X.copy()\n",
    "X_st[:, 2] = standard_scale(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1\n",
    "*Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logloss(y, y_pred):\n",
    "    if y_pred.dtype != 'float64':\n",
    "        y_pred = np.array([y_pred], dtype=np.float64) # в случае если y_pred окажутся int\n",
    "    y_pred[(y_pred>1-1e-10)] = 1-1e-10\n",
    "    y_pred[(y_pred<1e-10)] = 1e-10   \n",
    "    err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.array([1, 1])\n",
    "y_pred1 = np.array([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.51292546502023"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_logloss(y1, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2\n",
    "Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция потерь log loss монотонно убывающая функция зависящая от произведения <w,x>, поэтому её градиент ни когда не будет \n",
    "равен 0. И с ростом числа итераций модель стремясь продвинуться по градиентному спучку будет увеличивать вектор весов бесконечно. \n",
    "Поэтому формулировка задания на мой взгляд не совсем корректная. \n",
    "Чтобы определить минимальный log loss нужно ввести регуляризацию, котороя бы не позволила рости весам бесконечно, \n",
    "либо зафиксировать ошибку принудительно.\n",
    "Я решил пойти по второму пути. Зафиксировал ошибку на у провне 0,2877 (средняя вероятность р+ = 0.75, np.log(0.75)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_pred(X, y, eta, log=False):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    i = 0\n",
    "    err = 1\n",
    "    while err > 0.2877: # средняя вероятность P+ = 0.75\n",
    "        z = np.dot(X, W)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        dQ = 1/n * X.T @ (y_pred - y)\n",
    "        W -= eta * dQ\n",
    "        i +=1\n",
    "        if i % 10 == 0 and log:\n",
    "            print(i, W, err)\n",
    "    return i, eta, err, W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "обучим модель на разных скоростях обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = np.array([1e-3, 1e-2, 1e-1, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for el_eta in eta:\n",
    "    res.append(np.array(eval_model_pred(X_st, y, eta=el_eta), dtype='object'))\n",
    "res = np.array(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "рассмотрим res. Из 5 возможных вариантов при разной eta, мы сумели добиться необходимой нам ошибки. Хотя при eta > 1 можно наблюдать резкий рост значений весов. Поэтому в качестве оптимального выбираю \n",
    "eta = 1,\n",
    "iteretions = 359"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteretions, eta, err\n",
      "[[366446 0.001 0.28769988694018844]\n",
      " [36645 0.01 0.28769976681419374]\n",
      " [3665 0.1 0.2876968899115469]\n",
      " [359 1.0 0.2876633146052598]\n",
      " [126 2.0 0.287453191695589]\n",
      " [125 3.0 0.28429827382131223]]\n"
     ]
    }
   ],
   "source": [
    "print('Iteretions, eta, err')\n",
    "print(res[:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Веса W\n",
      "[array([-6.26210276, -1.06751079, -0.98117828,  5.65954682])\n",
      " array([-6.26219929, -1.06751589, -0.98121153,  5.65961737])\n",
      " array([-6.26326652, -1.06757252, -0.98157884,  5.66039777])\n",
      " array([-6.27422062, -1.06817129, -0.98531906,  5.66843845])\n",
      " array([-6.46935804, -1.2689934 , -0.72835177,  6.13799067])\n",
      " array([-10.12329296,  -2.08851649,  -0.99279209,  10.00304125])]\n"
     ]
    }
   ],
   "source": [
    "print('Веса W')\n",
    "print(res[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.27422062, -1.06817129, -0.98531906,  5.66843845])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = res[3,3]\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3\n",
    "Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(X, W):\n",
    "    z = np.dot(X, W)\n",
    "    y_pred = sigmoid(z) \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32987619, 0.24691228, 0.96718543, 0.00557079, 0.70949528,\n",
       "       0.43777942, 0.98691902, 0.11573679, 0.35271092, 0.94662261])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_pred_proba(X_st, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4\n",
    "Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(X, W, b=0.5):\n",
    "    y_predicted = np.zeros(X.shape[0])\n",
    "    z = np.dot(X, W)\n",
    "    y_pred = sigmoid(z) \n",
    "        # За порог отнесения к тому или иному классу примем вероятность 0.5\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        if (y_pred[i] > b): \n",
    "            y_predicted[i] = 1\n",
    "        elif (y_pred[i] <= b):\n",
    "            y_predicted[i] = 0\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 1. 0. 1. 0. 0. 1.]\n",
      "[0. 0. 1. 0. 1. 0. 1. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(calc_pred(X_st, W, 0.5))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5\n",
    "*Реализуйте функции для подсчета Accuracy, матрицы ошибок, точности и полноты, а также F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = calc_pred(X_st, W, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, y_pred):\n",
    "    acu = 1 - np.mean(np.abs(y-y_pred))\n",
    "    return acu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy: {accuracy(y, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### матрица ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_err(y, y_pred):\n",
    "    m = y.shape[0]\n",
    "    mx = np.zeros((2,2))\n",
    "    for index in range(m):\n",
    "            if y[index]==1 and y_pred[index]==1:\n",
    "                mx[0,0] +=1\n",
    "            if y[index]==0 and y_pred[index]==0:\n",
    "                mx[1,1] +=1\n",
    "            if y[index]==0 and y_pred[index]==1:\n",
    "                mx[0,1] +=1\n",
    "            if y[index]==1 and y_pred[index]==0:\n",
    "                mx[1,0] +=1                \n",
    "    return mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "матрица ошибок:\n",
      " [[4. 0.]\n",
      " [1. 5.]]\n"
     ]
    }
   ],
   "source": [
    "print(f'матрица ошибок:\\n {matrix_err(y, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Полнота"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y, y_pred):\n",
    "    mx = matrix_err(y, y_pred)\n",
    "    return mx[0,0]/(mx[0,0]+mx[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Полнота (recall): 0.8\n"
     ]
    }
   ],
   "source": [
    "print(f'Полнота (recall): {recall(y, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Точность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y, y_pred):\n",
    "    mx = matrix_err(y, y_pred)\n",
    "    return mx[0,0]/(mx[0,0]+mx[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность (precision): 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Точность (precision): {precision(y, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_score(y, y_pred, b=1):\n",
    "    r = recall(y, y_pred)\n",
    "    p = precision(y, y_pred)\n",
    "    res = (1+b**2)*(r*p)/(b**2*𝑝+r)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_score: 0.888888888888889\n"
     ]
    }
   ],
   "source": [
    "print(f'f_score: {f_score(y, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 6\n",
    "Могла ли модель переобучиться? Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, могла.\n",
    "\n",
    "Функция потерь log loss монотонно убывающая функция зависящая от произведения <w,x>, \n",
    "поэтому её градиент ни когда не будет равен 0. И с ростом числа итераций модель стремясь продвинуться по градиентному спуску будет увеличивать W бесконечно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
